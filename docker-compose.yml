version: '3.8'

services:
  chatterbox-tts-server:
    build:
      context: .
      dockerfile: Dockerfile

    ports:
      - "${PORT:-8004}:8004"
    volumes:
      # Mount local config file for persistence
      - ./config.yaml:/app/config.yaml
      # Mount local directories for persistent app data
      - ./voices:/app/voices
      - ./reference_audio:/app/reference_audio
      - ./outputs:/app/outputs
      - ./logs:/app/logs

    # --- GPU Access ---
    # Modern method (Recommended for newer Docker/NVIDIA setups)
    devices:
      - nvidia.com/gpu=all
    device_cgroup_rules:
      - "c 195:* rmw" # Needed for some NVIDIA container toolkit versions
      - "c 236:* rmw" # Needed for some NVIDIA container toolkit versions

    # Legacy method (Alternative for older Docker/NVIDIA setups)
    # If the 'devices' block above doesn't work, comment it out and uncomment
    # the 'deploy' block below. Do not use both simultaneously.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1 # Or specify specific GPUs e.g., "device=0,1"
    #           capabilities: [gpu]
    # --- End GPU Access ---

    restart: unless-stopped
    environment:
      # Enable faster Hugging Face downloads inside the container
      - HF_HUB_ENABLE_HF_TRANSFER=1
      # Make NVIDIA GPUs visible and specify capabilities for PyTorch
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
